# LLM Alignment Assistant

## ğŸŒŸ Overview

**LLM Alignment Assistant** is an advanced tool designed to assist in aligning large language models (LLMs) with desired human values and objectives. This project offers a full-stack approach to training, fine-tuning, deploying, and monitoring LLMs using **Reinforcement Learning from Human Feedback (RLHF)**. The system also incorporates evaluation metrics to ensure ethical and effective use of language models. The assistant provides a user-friendly interface for exploring the alignment, visualization of training metrics, and deploying the system at scale using cloud-native technologies.

![âœ¨ Architecture Diagram](assets/architecture_diagram.png)

## âœ¨ Key Features

- **ğŸ–¥ï¸ User-Friendly Web Interface**: A sleek, intuitive UI for interacting with the LLM and viewing alignment results.
- **ğŸ“Š Interactive Training**: Train models using RLHF, with dynamic metrics displayed in real-time.
- **ğŸ› ï¸ Data Augmentation & Preprocessing**: Advanced preprocessing scripts, including tokenization, cleaning, and data augmentation using NLP techniques.
- **âš™ï¸ Scalable Deployment**: Easy deployment via Docker and Kubernetes, with horizontal scaling capabilities.
- **ğŸ” Explainability & Monitoring**: Incorporates SHAP or LIME-based explainability features along with live monitoring dashboards.

## ğŸ—‚ï¸ Project Structure

- **ğŸ“ app/**: Contains the UI and the backend logic of the web interface.
  - `ui.py`: Manages routes and interactions with the UI.
  - `static/`: Contains styles and JavaScript for an appealing UI.
  - `templates/`: HTML templates for rendering the web pages.
- **ğŸ“ data/**: Scripts and datasets for generating, downloading, and processing data.
- **ğŸ“ deployment/**: Docker, Kubernetes configurations, and Helm charts to manage deployments.
- **ğŸ“ src/**: Core functionality, including training, evaluation, and preprocessing scripts.
- **ğŸ“ tests/**: Unit and integration tests to ensure quality across the different components.

## ğŸ› ï¸ Setup

### ğŸ“‹ Prerequisites

- Python 3.8+
- Docker & Docker Compose
- Kubernetes (Minikube or any cloud provider)
- Node.js (for front-end enhancements)

### ğŸ”§ Installation

1. **ğŸ“¥ Clone the Repository**:
   ```bash
   git clone https://github.com/yourusername/LLM-Alignment-Assistant.git
   cd LLM-Alignment-Assistant
   ```

2. **ğŸ“¦ Set Up the Virtual Environment**:
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```

3. **ğŸ“¦ Install Node.js Dependencies** (optional for enhanced UI):
   ```bash
   cd app/static
   npm install
   ```

### ğŸš€ Running Locally

To run the application locally:

1. **ğŸ³ Build Docker Image**:
   ```bash
   docker-compose up --build
   ```

2. **ğŸŒ Access the UI**:
   Visit `http://localhost:5000` in your web browser.

## ğŸ“¦ Deployment

### ğŸš¢ Docker and Kubernetes

- **ğŸ³ Docker**: A Dockerfile is provided for containerization.
- **â˜¸ï¸ Kubernetes**: Use the provided `deployment/kubernetes/deployment.yml` and `service.yml` files to deploy the app to a Kubernetes cluster.
- **ğŸ“œ Helm Charts**: Helm charts are available in the `deployment/helm/` directory for easier reusability and scalability.

### ğŸ”„ CI/CD Pipeline

A GitHub Actions workflow is included to automate building, testing, and deployment:

- **âœ… Lint & Test**: Linting and unit tests are run at every pull request.
- **ğŸ‹ Docker Build & Push**: Docker images are built and pushed to Docker Hub.
- **â˜¸ï¸ Kubernetes Deployment**: Automatically deploy to the Kubernetes cluster upon merging.

## ğŸ¤– Training and Fine-Tuning

### ğŸ’¡ Reinforcement Learning from Human Feedback (RLHF)

The training module includes:
- **ğŸ“Š Fine-Tuning**: Using the `training/fine_tuning.py` script, models can be fine-tuned on specific datasets.
- **ğŸ† Reward Models**: Implemented in `training/reward_model.py` for evaluating the appropriateness of responses.
- **ğŸŒ Distributed Training**: Support for distributed training using `training/rlhf.py`.

### ğŸ›ï¸ Hyperparameter Tuning

For hyperparameter tuning, **Optuna** has been integrated to provide automated exploration of the training parameters, ensuring optimal model performance.

## ğŸ”„ Data Pipeline

- **ğŸ› ï¸ Data Augmentation**: Using advanced NLP techniques, including back-translation and embedding-based masking, available in `preprocessing/augmentation.py`.
- **âœ… Validation**: Thorough validation scripts (`preprocess_data.py` and `validate_data.py`) to maintain data quality.
- **âš™ï¸ Automation with Apache Airflow**: Data pipeline orchestration using Airflow, ensuring proper data flow between stages.

## ğŸ“ˆ Evaluation and Monitoring

- **ğŸ“Š Metrics**: The `evaluation/metrics.py` script provides a detailed analysis of model performance, including bias detection and fairness metrics.
- **ğŸ›¡ï¸ Safety Testing**: Ethical AI assessments using `evaluation/safety_tests.py`.
- **ğŸ“Š Dashboard**: Real-time monitoring with **Streamlit**, displaying key metrics, including training loss, accuracy, and reward trends.

## ğŸŒ Web Interface Improvements

- **ğŸ¨ Improved UI with TailwindCSS**: We've enhanced the CSS for modern and engaging aesthetics.
- **ğŸ“ˆ Interactive Visualizations**: Added **Chart.js** visualizations to present alignment metrics in a clear, graphical format.
- **ğŸ’¬ Chatbot Integration**: A conversational UI element to interact directly with the trained LLM.

## ğŸ§ª Testing

- **âœ… Unit Tests**: Located in `tests/`, covering training, preprocessing, and evaluation.
- **ğŸ”„ Integration Tests**: End-to-end tests that simulate full pipeline execution.
- **ğŸ§ª Mock Testing**: Use of `pytest-mock` to simulate API calls and external integrations.

## ğŸ“Š Monitoring and Logging

- **ğŸ“ˆ Monitoring**: Kubernetes monitoring using **Prometheus** and **Grafana**, with Horizontal Pod Autoscaling (HPA) for scalability.
- **ğŸ” Explainability**: SHAP and LIME explainability metrics are added to the evaluation process, providing insights into model behavior.
- **ğŸ“œ Logging**: Centralized logging using **ELK Stack** (Elasticsearch, Logstash, Kibana).

## ğŸš€ Cloud Deployment Instructions (AWS)

To deploy the LLM Alignment Assistant on **AWS**, you can utilize **Elastic Kubernetes Service (EKS)** or **AWS Sagemaker** for model training:

1. **AWS Elastic Kubernetes Service (EKS)**:
   - Create an EKS cluster using AWS CLI or the console.
   - Apply the Kubernetes deployment files:
     ```bash
     kubectl apply -f deployment/kubernetes/deployment.yml
     kubectl apply -f deployment/kubernetes/service.yml
     ```
   - Configure the **Horizontal Pod Autoscaler (HPA)** to ensure scalability:
     ```bash
     kubectl apply -f deployment/kubernetes/hpa.yml
     ```

2. **AWS Sagemaker for Model Training**:
   - Modify the `training/fine_tuning.py` to integrate with AWS Sagemaker.
   - Use the Sagemaker Python SDK to launch a training job:
     ```python
     import sagemaker
     from sagemaker.pytorch import PyTorch

     role = "arn:aws:iam::your-account-id:role/service-role/AmazonSageMaker-ExecutionRole-2023"

     pytorch_estimator = PyTorch(
         entry_point='training/fine_tuning.py',
         role=role,
         instance_count=1,
         instance_type='ml.p2.xlarge',
         framework_version='1.8.0',
         py_version='py3'
     )

     pytorch_estimator.fit({'training': 's3://your-bucket-name/training-data'})
     ```
   - Ensure IAM roles and permissions are properly set for accessing **S3** and **Sagemaker**.


## ğŸš€ Future Work

- **ğŸŒ Multi-Language Support**: Expand the LLM's training to support multiple languages.
- **âš–ï¸ Ethical AI Enhancements**: Further enhance bias detection and mitigation techniques.
- **â˜ï¸ Cloud-Native Deployment**: Implement cloud services like **AWS SageMaker** for training at scale.

## ğŸ¤ Getting Involved

Contributions are welcome! Feel free to submit issues, pull requests, or suggestions for new features. 

## ğŸ“œ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.

## ğŸ“¬ Contact

- **âœ‰ï¸ Email**: [amirsina.torfi@gmail.com](mailto:amirsina.torfi@gmail.com)
- **ğŸŒ Website**: [Portfolio](https://astorfi.github.io)

---

<p align="center">Made with â¤ï¸ by Amirsina Torfi</p>

